{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:dodgerblue; font-weight:700\"> Sentiment Analysis on Twitter Tweets</h1>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sentiment Analysis is conducted on various datasets after exploratory data analysis and data preprocessing, separately using variety of Machine Learning techniques</p>\n",
    "<h4 style=\"font-weight:600;\">15 implemented ML Algorithms : </h4>\n",
    "<ol>\n",
    "<li>Logistic Regression</li>\n",
    "<ul>\n",
    "<li>Newton CG</li>\n",
    "<li>SAG</li>\n",
    "<li>SAGA</li>\n",
    "<li>LBFGS</li>\n",
    "</ul>\n",
    "<li>Decision Tree Classifier</li>\n",
    "<li>Support Vector Machines</li>\n",
    "<ul>\n",
    "<li>Linear</li>\n",
    "<li>Poly</li>\n",
    "<li>RBF</li>\n",
    "<li>Sigmoid</li>\n",
    "</ul>\n",
    "<li>Majority Voting Ensemble</li>\n",
    "<li>Extreme Laerning Machines</li>\n",
    "<ul>\n",
    "<li>Tanh</li>\n",
    "<li>SinSQ</li>\n",
    "<li>Tribas</li>\n",
    "<li>Hardlim</li>\n",
    "</ul>\n",
    "<li>Artificial Neural Networks (Multi - Layer Perceptron) Gradient Descent</li>\n",
    "</ol>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<h2 align=\"center\" style=\"color:red\">Part 1 : Data Preprocessing</h2>\n",
    "<ol>\n",
    "<li>Exploratory Data Analysis</li>\n",
    "<li>Data Preprocessing</li>\n",
    "<li>Cleaning</li>\n",
    "<li>Lemmatization</li>\n",
    "</ol>\n",
    "<h4 style=\"font-weight:700\">>>> Run Text_Preprocessing_MP_Hybrid.py if you want to Preprocess some datasets</h4>\n",
    "<hr/>\n",
    "<style>\n",
    "li {\n",
    "    margin-left:100px;\n",
    "    /* color: yellow; */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Flow of Control</h4>\n",
    "<ol>\n",
    "<li>Sentence Segmentation</li>\n",
    "<li>Word Tokenization</li>\n",
    "<li>Same consecutive chars changed to max 2 times</li>\n",
    "<li>Spelling Corrections</li>\n",
    "<li>Removal of #Hashtags, @Mentions, http//:URLs, etc (Noise 1)</li>\n",
    "<li>Removal of Special Unicode Characters (Noise 2)</li>\n",
    "<li>Chat Abbreviations conversions (Noise 3)</li>\n",
    "<li>Removal of Punctuations except `'` (Noise 4)</li>\n",
    "<li>Stop Words Removal (Noise 5)</li>\n",
    "<li>Parts of Speech Tagging</li>\n",
    "<li>Stemming & Lemmatization</li>\n",
    "<li>WhiteSpace Removals</li>\n",
    "<li>Chunking</li>\n",
    "</ol>\n",
    "<hr/>\n",
    "<style>\n",
    "h4 {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    color: green;\n",
    "    font-weight: 650;\n",
    "}\n",
    "li {\n",
    "    margin-left:100px;\n",
    "    /* color: yellow; */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:red\">Part 2 : Machine Learning Models Training</h2>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neccessary Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            filePath : str = \"\",\n",
    "            df : pd.DataFrame = None,\n",
    "            preprocessed : str = True,\n",
    "            name : str = \"\"\n",
    "        ) -> None:\n",
    "        \"\"\"Dataset\n",
    "            ======\n",
    "            Represents AI-ML datasets\n",
    "\n",
    "            Paramters\n",
    "            ---------\n",
    "            filePath : str - System Path to the file location (default '')\n",
    "            df : pd.DataFrame - Pandas DataFrame for the dataset (default None)\n",
    "            preprocessed : str - Indicates whether data is raw or processed, Possible values = ('raw', 'pro')\n",
    "            name : str - Given name for the dataset\n",
    "        \"\"\"\n",
    "        self.filePath = filePath\n",
    "        self.name = name if name else filePath\n",
    "        self.df = df\n",
    "        self.preprocessed = preprocessed\n",
    "    \n",
    "\n",
    "\n",
    "    def loadDataset(self, filePath : str = 'default'):\n",
    "        if filePath:\n",
    "            self.filePath = filePath\n",
    "            if not self.name: self.name = filePath\n",
    "        if self.filePath is None:\n",
    "            raise(\"Path to dataset file not provided\")\n",
    "        try:\n",
    "            self.df = pd.read_csv(filePath)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot import dataset named {self.name} from path {self.filePath}\")\n",
    "            print(f\"Original Error : {e}\")\n",
    "            traceback.print_exception()\n",
    "    \n",
    "\n",
    "    def get_DF(self):\n",
    "        if self.df is None:\n",
    "            self.loadDataset()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"dataset_1\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_1_processed.csv\", name = \"dataset_1\"),\n",
    "        \"trainingDone\" : True\n",
    "    },\n",
    "\n",
    "    \"dataset_2\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_2_processed.csv\", name = \"dataset_2\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "\n",
    "    \"dataset_3\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_3_processed.csv\", name = \"dataset_3\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "\n",
    "    \"dataset_4\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_4_processed.csv\", name = \"dataset_4\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTwe = pd.read_csv(\"./data/dataset_3_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dfTwe.index:\n",
    "    if type(dfTwe.loc[idx, \"Proc_Tweet\"]) != str:\n",
    "        dfTwe.loc[idx, \"Proc_Tweet\"] = \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10001\n",
       "Name: Proc_Tweet, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTwe[\"Proc_Tweet\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digitalize Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\n",
    "    'fun' : 1, 'happiness' : 1, 'love' : 1, 'relief' : 1, 'enthusiasm' : 1, 'surprise' : 1,\n",
    "    'empty' : 0, 'neutral' : 0,\n",
    "    'boredom' : -1, 'anger' : -1, 'hate' : -1, 'sadness' : -1, 'worry' : -1\n",
    "}\n",
    "\n",
    "def digitalize(sent : str):\n",
    "    return sents.get(sent, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(dfTwe.loc[0, \"sentiment\"]) == str:\n",
    "    dfTwe[\"sentiment\"] = dfTwe[\"sentiment\"].apply(digitalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfTwe[\"Proc_Tweet\"][:10000]\n",
    "y = dfTwe[\"sentiment\"] [:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500,), (2500,), (7500,), (2500,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(ML_Model, y_test, y_pred):\n",
    "    results = {\n",
    "        \"ML Model\" : ML_Model,\n",
    "        \"classification_report\"  : classification_report(y_test, y_pred),\n",
    "        \"accuracy_score\"  : accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    funcs = (precision_score, recall_score, f1_score,)\n",
    "    params = (\"micro\", \"macro\", \"weighted\",)\n",
    "\n",
    "    for func in funcs:\n",
    "        results[func.__name__] = {}\n",
    "        for param in params:\n",
    "            results[func.__name__][param] = func(y_test, y_pred, average = param)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Classifier(ML_Method, x_train = x_train, x_test = x_test, y_train = y_train, y_test = y_test):\n",
    "    model = make_pipeline(TfidfVectorizer(ngram_range=(1, 3)), ML_Method)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return generate_results(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGR_solvers = ('newton-cg', 'sag', 'saga', 'lbfgs',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slvr in LOGR_solvers:\n",
    "    result_LOGR = Text_Classifier(LogisticRegression(random_state = 0, solver = slvr, multi_class = 'auto'))\n",
    "    ML_results[f\"LOGR_{slvr}\"] = result_LOGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_DT = Text_Classifier(DecisionTreeClassifier())\n",
    "ML_results['Decision_Tree'] = result_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_Kernels = ['linear', 'poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for krnl in SVM_Kernels:\n",
    "    try:\n",
    "        result_SVM = Text_Classifier(SVC(kernel=krnl))\n",
    "        ML_results[f\"SVM_{krnl}\"] = result_SVM\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_MVE = Text_Classifier(VotingClassifier(estimators = [\n",
    "    ('lr', LogisticRegression(random_state = 0, solver = 'lbfgs', multi_class = 'auto')),\n",
    "    ('svm', SVC(kernel=\"rbf\"))\n",
    "]))\n",
    "ML_results[\"MVE\"] = result_MVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Learning Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ELM(10,tanh) Successful, metrics saved\n",
      "Model ELM(10,tanh,LR) Successful, metrics saved\n",
      "Model ELM(10,sinsq) Successful, metrics saved\n",
      "Model ELM(10,tribas) Successful, metrics saved\n",
      "Model ELM(hardlim) Successful, metrics saved\n",
      "Model ELM(20,rbf(0.1)) failed with error : unsupported operand type(s) for -: 'map' and 'map'\n"
     ]
    }
   ],
   "source": [
    "def make_classifiers():\n",
    "    nh : int = 10\n",
    "\n",
    "    # Custom (user defined) transfer function\n",
    "    sinsq = (lambda x: np.power(np.sin(x), 2.0))\n",
    "    srhl_sinsq = MLPRandomLayer(n_hidden=nh, activation_func=sinsq)\n",
    "\n",
    "    # Internal Transfer functions\n",
    "    srhl_tanh = MLPRandomLayer(n_hidden=nh, activation_func='tanh')\n",
    "    srhl_tribas = MLPRandomLayer(n_hidden=nh, activation_func='tribas')\n",
    "    srhl_hardlim = MLPRandomLayer(n_hidden=nh, activation_func='hardlim')\n",
    "\n",
    "    # Gaussian RBF\n",
    "    srhl_rbf = RBFRandomLayer(n_hidden=nh*2, rbf_width=0.1, random_state=0)\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    classifiers = [\n",
    "        ('ELM(10,tanh)', GenELMClassifier(hidden_layer=srhl_tanh)),\n",
    "        ('ELM(10,tanh,LR)', GenELMClassifier(hidden_layer=srhl_tanh, regressor=log_reg)),\n",
    "        ('ELM(10,sinsq)', GenELMClassifier(hidden_layer=srhl_sinsq)),\n",
    "        ('ELM(10,tribas)', GenELMClassifier(hidden_layer=srhl_tribas)),\n",
    "        ('ELM(hardlim)', GenELMClassifier(hidden_layer=srhl_hardlim)),\n",
    "        ('ELM(20,rbf(0.1))', GenELMClassifier(hidden_layer=srhl_rbf)),\n",
    "    ]\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = [dfTwe[\"Proc_Tweet\"].to_list(), dfTwe[\"sentiment\"].to_list()]\n",
    "    names, classifiers = zip(*make_classifiers())\n",
    "\n",
    "\n",
    "    X, y = dataset\n",
    "    vectorizer = TfidfVectorizer(min_df=3, sublinear_tf=True, norm='l2', ngram_range=(1, 3))\n",
    "    X = vectorizer.fit_transform(X)[:10000]\n",
    "    y = y[:10000]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=3)\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        try:\n",
    "            clf.fit(x_train, y_train)\n",
    "            # score = clf.score(x_test, y_test)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            print(f'Model {name} Successful, metrics saved')\n",
    "            ML_results[name] = generate_results(clf, y_test, y_pred)\n",
    "\n",
    "        except Exception as e: print(f'Model {name} failed with error : {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfTwe[\"Proc_Tweet\"]#[:10000]\n",
    "y = dfTwe[\"sentiment\"] #[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 4146), (2501, 4146), (7500,), (2501,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='sgd', random_state=20, hidden_layer_sizes=(15,12), alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 12), random_state=20,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 10000\n",
    "clf.fit(x_train[:sz], y_train[:sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results['ANN-GD'] = generate_results(clf, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Metrics Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- LOGR_newton-cg --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='newton-cg'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       1.00      0.08      0.15       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.97      0.54      0.56      2500\n",
      "weighted avg       0.94      0.94      0.91      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9368\n",
      "precision_score\n",
      "{'micro': 0.9368, 'macro': 0.9682220434432824, 'weighted': 0.9408167337087691}\n",
      "recall_score\n",
      "{'micro': 0.9368, 'macro': 0.5406976744186046, 'weighted': 0.9368}\n",
      "f1_score\n",
      "{'micro': 0.9368, 'macro': 0.5588583477402379, 'weighted': 0.9109941309174406}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_sag --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='sag'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       1.00      0.08      0.15       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.97      0.54      0.56      2500\n",
      "weighted avg       0.94      0.94      0.91      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9368\n",
      "precision_score\n",
      "{'micro': 0.9368, 'macro': 0.9682220434432824, 'weighted': 0.9408167337087691}\n",
      "recall_score\n",
      "{'micro': 0.9368, 'macro': 0.5406976744186046, 'weighted': 0.9368}\n",
      "f1_score\n",
      "{'micro': 0.9368, 'macro': 0.5588583477402379, 'weighted': 0.9109941309174406}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_saga --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='saga'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       1.00      0.08      0.15       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.97      0.54      0.56      2500\n",
      "weighted avg       0.94      0.94      0.91      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9368\n",
      "precision_score\n",
      "{'micro': 0.9368, 'macro': 0.9682220434432824, 'weighted': 0.9408167337087691}\n",
      "recall_score\n",
      "{'micro': 0.9368, 'macro': 0.5406976744186046, 'weighted': 0.9368}\n",
      "f1_score\n",
      "{'micro': 0.9368, 'macro': 0.5588583477402379, 'weighted': 0.9109941309174406}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_lbfgs --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression', LogisticRegression(random_state=0))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       1.00      0.08      0.15       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.97      0.54      0.56      2500\n",
      "weighted avg       0.94      0.94      0.91      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9368\n",
      "precision_score\n",
      "{'micro': 0.9368, 'macro': 0.9682220434432824, 'weighted': 0.9408167337087691}\n",
      "recall_score\n",
      "{'micro': 0.9368, 'macro': 0.5406976744186046, 'weighted': 0.9368}\n",
      "f1_score\n",
      "{'micro': 0.9368, 'macro': 0.5588583477402379, 'weighted': 0.9109941309174406}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- Decision_Tree --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('decisiontreeclassifier', DecisionTreeClassifier())])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      2328\n",
      "           1       0.42      0.42      0.42       172\n",
      "\n",
      "    accuracy                           0.92      2500\n",
      "   macro avg       0.69      0.69      0.69      2500\n",
      "weighted avg       0.92      0.92      0.92      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9196\n",
      "precision_score\n",
      "{'micro': 0.9196, 'macro': 0.6866055925538601, 'weighted': 0.9198163364971645}\n",
      "recall_score\n",
      "{'micro': 0.9196, 'macro': 0.6876098857188524, 'weighted': 0.9196}\n",
      "f1_score\n",
      "{'micro': 0.9196, 'macro': 0.6871059636669312, 'weighted': 0.9197078858637276}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_linear --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='linear'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2328\n",
      "           1       0.85      0.31      0.45       172\n",
      "\n",
      "    accuracy                           0.95      2500\n",
      "   macro avg       0.90      0.65      0.71      2500\n",
      "weighted avg       0.94      0.95      0.94      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9488\n",
      "precision_score\n",
      "{'micro': 0.9488, 'macro': 0.9030141046336235, 'weighted': 0.944560565243854}\n",
      "recall_score\n",
      "{'micro': 0.9488, 'macro': 0.6521367777511389, 'weighted': 0.9488}\n",
      "f1_score\n",
      "{'micro': 0.9488, 'macro': 0.7130672749640437, 'weighted': 0.9373566638332058}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_poly --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='poly'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       0.88      0.17      0.29       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.91      0.59      0.63      2500\n",
      "weighted avg       0.94      0.94      0.92      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9416\n",
      "precision_score\n",
      "{'micro': 0.9416, 'macro': 0.9123849053003197, 'weighted': 0.9382844711607271}\n",
      "recall_score\n",
      "{'micro': 0.9416, 'macro': 0.5863501957963718, 'weighted': 0.9416}\n",
      "f1_score\n",
      "{'micro': 0.9416, 'macro': 0.6304037004184032, 'weighted': 0.9228793856398168}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_rbf --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC())])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       0.97      0.17      0.29       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.95      0.58      0.63      2500\n",
      "weighted avg       0.94      0.94      0.92      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9424\n",
      "precision_score\n",
      "{'micro': 0.9424, 'macro': 0.9543859649122808, 'weighted': 0.9437950877192983}\n",
      "recall_score\n",
      "{'micro': 0.9424, 'macro': 0.584087548949093, 'weighted': 0.9424}\n",
      "f1_score\n",
      "{'micro': 0.9424, 'macro': 0.6285581038303913, 'weighted': 0.923006810593523}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_sigmoid --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='sigmoid'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      2328\n",
      "           1       0.88      0.25      0.39       172\n",
      "\n",
      "    accuracy                           0.95      2500\n",
      "   macro avg       0.91      0.62      0.68      2500\n",
      "weighted avg       0.94      0.95      0.93      2500\n",
      "\n",
      "accuracy_score\n",
      "0.946\n",
      "precision_score\n",
      "{'micro': 0.946, 'macro': 0.9124597207303974, 'weighted': 0.942564983888292}\n",
      "recall_score\n",
      "{'micro': 0.946, 'macro': 0.6237113402061856, 'weighted': 0.946}\n",
      "f1_score\n",
      "{'micro': 0.946, 'macro': 0.6804458419612956, 'weighted': 0.9316677659329704}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- MVE --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('votingclassifier',\n",
      "                 VotingClassifier(estimators=[('lr',\n",
      "                                               LogisticRegression(random_state=0)),\n",
      "                                              ('svm', SVC())]))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2328\n",
      "           1       1.00      0.08      0.14       172\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.97      0.54      0.55      2500\n",
      "weighted avg       0.94      0.94      0.91      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9364\n",
      "precision_score\n",
      "{'micro': 0.9364, 'macro': 0.9680337756332931, 'weighted': 0.9404661037394452}\n",
      "recall_score\n",
      "{'micro': 0.9364, 'macro': 0.5377906976744186, 'weighted': 0.9364}\n",
      "f1_score\n",
      "{'micro': 0.9364, 'macro': 0.553759366843479, 'weighted': 0.9101192826471334}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,tanh) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2323\n",
      "           1       0.17      0.01      0.01       177\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.55      0.50      0.49      2500\n",
      "weighted avg       0.88      0.93      0.90      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9276\n",
      "precision_score\n",
      "{'micro': 0.9276, 'macro': 0.5480486500935579, 'weighted': 0.8754269446672013}\n",
      "recall_score\n",
      "{'micro': 0.9276, 'macro': 0.5017486641810828, 'weighted': 0.9276}\n",
      "f1_score\n",
      "{'micro': 0.9276, 'macro': 0.48667685372048675, 'weighted': 0.8950588441891252}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,tanh,LR) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2323\n",
      "           1       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.46      0.50      0.48      2500\n",
      "weighted avg       0.86      0.93      0.90      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9292\n",
      "precision_score\n",
      "{'micro': 0.9292, 'macro': 0.4646, 'weighted': 0.8634126400000001}\n",
      "recall_score\n",
      "{'micro': 0.9292, 'macro': 0.5, 'weighted': 0.9292}\n",
      "f1_score\n",
      "{'micro': 0.9292, 'macro': 0.48165042504665145, 'weighted': 0.8950991499066971}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,sinsq) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2323\n",
      "           1       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.46      0.50      0.48      2500\n",
      "weighted avg       0.86      0.93      0.90      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9292\n",
      "precision_score\n",
      "{'micro': 0.9292, 'macro': 0.4646, 'weighted': 0.8634126400000001}\n",
      "recall_score\n",
      "{'micro': 0.9292, 'macro': 0.5, 'weighted': 0.9292}\n",
      "f1_score\n",
      "{'micro': 0.9292, 'macro': 0.48165042504665145, 'weighted': 0.8950991499066971}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,tribas) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2323\n",
      "           1       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.46      0.50      0.48      2500\n",
      "weighted avg       0.86      0.93      0.90      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9292\n",
      "precision_score\n",
      "{'micro': 0.9292, 'macro': 0.4646, 'weighted': 0.8634126400000001}\n",
      "recall_score\n",
      "{'micro': 0.9292, 'macro': 0.5, 'weighted': 0.9292}\n",
      "f1_score\n",
      "{'micro': 0.9292, 'macro': 0.48165042504665145, 'weighted': 0.8950991499066971}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(hardlim) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2323\n",
      "           1       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.93      2500\n",
      "   macro avg       0.46      0.50      0.48      2500\n",
      "weighted avg       0.86      0.93      0.90      2500\n",
      "\n",
      "accuracy_score\n",
      "0.9292\n",
      "precision_score\n",
      "{'micro': 0.9292, 'macro': 0.4646, 'weighted': 0.8634126400000001}\n",
      "recall_score\n",
      "{'micro': 0.9292, 'macro': 0.5, 'weighted': 0.9292}\n",
      "f1_score\n",
      "{'micro': 0.9292, 'macro': 0.48165042504665145, 'weighted': 0.8950991499066971}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ANN-GD --------------------------------------------------\n",
      "ML Model\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 12), random_state=20,\n",
      "              solver='sgd')\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2340\n",
      "           1       0.00      0.00      0.00       161\n",
      "\n",
      "    accuracy                           0.94      2501\n",
      "   macro avg       0.47      0.50      0.48      2501\n",
      "weighted avg       0.88      0.94      0.90      2501\n",
      "\n",
      "accuracy_score\n",
      "0.9356257497001199\n",
      "precision_score\n",
      "{'micro': 0.9356257497001199, 'macro': 0.46781287485005996, 'weighted': 0.8753955435019115}\n",
      "recall_score\n",
      "{'micro': 0.9356257497001199, 'macro': 0.5, 'weighted': 0.9356257497001199}\n",
      "f1_score\n",
      "{'micro': 0.9356257497001199, 'macro': 0.48337120429663294, 'weighted': 0.9045090908069741}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for meth, result in ML_results.items():\n",
    "    try:\n",
    "        print('-'*50 + \" \" + meth + \" \" + '-'*50)\n",
    "        for k, v in result.items():\n",
    "            try:\n",
    "                print(k)\n",
    "                print(v)\n",
    "            except: pass\n",
    "        print('-'*100)\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Centred Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = {\n",
    "    'ML Method' : [],\n",
    "    'Accuracy' : [],\n",
    "    'Precision' : [],\n",
    "    'Recall' : [],\n",
    "    'F1-Score' : [],\n",
    "}\n",
    "\n",
    "for meth, result in ML_results.items():\n",
    "    metrics_table['ML Method'].append(meth)\n",
    "    metrics_table['Accuracy'].append(result['accuracy_score'])\n",
    "    metrics_table['Precision'].append(max(result['precision_score'].values()))\n",
    "    metrics_table['Recall'].append(max(result['recall_score'].values()))\n",
    "    metrics_table['F1-Score'].append(max(result['f1_score'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df_metrics.index:\n",
    "    df_metrics.loc[idx, :] = df_metrics.loc[idx, :].apply(lambda val : val.replace('_', ' - ').upper() if type(val) == str else val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(x):\n",
    "    df_metrics.style.set_properties(**{'color': 'cyan'}, subset=['ML Method'])\n",
    "    # mask  =  df_metrics['Win %'] > 0\n",
    "    # mask1 =  df_metrics['Win %'] == 0\n",
    "    # mask2 =  df_metrics['Win %'] < 0\n",
    "    x = pd.DataFrame('', index=df_metrics.index, columns=df_metrics.columns)\n",
    "    x.loc[:, 'ML Method'] = 'color: cyan'\n",
    "    # x.loc[mask1,['Win %']] = 'color: cyan'\n",
    "    # x.loc[mask2,['Win %']] = 'color: red'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ea3f6_row0_col0,#T_ea3f6_row1_col0,#T_ea3f6_row2_col0,#T_ea3f6_row3_col0,#T_ea3f6_row4_col0,#T_ea3f6_row5_col0,#T_ea3f6_row6_col0,#T_ea3f6_row7_col0,#T_ea3f6_row8_col0,#T_ea3f6_row9_col0,#T_ea3f6_row10_col0,#T_ea3f6_row11_col0,#T_ea3f6_row12_col0,#T_ea3f6_row13_col0,#T_ea3f6_row14_col0,#T_ea3f6_row15_col0{\n",
       "            color:  cyan;\n",
       "        }</style><table id=\"T_ea3f6_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >ML Method</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >F1-Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ea3f6_row0_col0\" class=\"data row0 col0\" >LOGR - NEWTON-CG</td>\n",
       "                        <td id=\"T_ea3f6_row0_col1\" class=\"data row0 col1\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row0_col2\" class=\"data row0 col2\" >0.968222</td>\n",
       "                        <td id=\"T_ea3f6_row0_col3\" class=\"data row0 col3\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row0_col4\" class=\"data row0 col4\" >0.936800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_ea3f6_row1_col0\" class=\"data row1 col0\" >LOGR - SAG</td>\n",
       "                        <td id=\"T_ea3f6_row1_col1\" class=\"data row1 col1\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row1_col2\" class=\"data row1 col2\" >0.968222</td>\n",
       "                        <td id=\"T_ea3f6_row1_col3\" class=\"data row1 col3\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row1_col4\" class=\"data row1 col4\" >0.936800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_ea3f6_row2_col0\" class=\"data row2 col0\" >LOGR - SAGA</td>\n",
       "                        <td id=\"T_ea3f6_row2_col1\" class=\"data row2 col1\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row2_col2\" class=\"data row2 col2\" >0.968222</td>\n",
       "                        <td id=\"T_ea3f6_row2_col3\" class=\"data row2 col3\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row2_col4\" class=\"data row2 col4\" >0.936800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_ea3f6_row3_col0\" class=\"data row3 col0\" >LOGR - LBFGS</td>\n",
       "                        <td id=\"T_ea3f6_row3_col1\" class=\"data row3 col1\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row3_col2\" class=\"data row3 col2\" >0.968222</td>\n",
       "                        <td id=\"T_ea3f6_row3_col3\" class=\"data row3 col3\" >0.936800</td>\n",
       "                        <td id=\"T_ea3f6_row3_col4\" class=\"data row3 col4\" >0.936800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_ea3f6_row4_col0\" class=\"data row4 col0\" >DECISION - TREE</td>\n",
       "                        <td id=\"T_ea3f6_row4_col1\" class=\"data row4 col1\" >0.919600</td>\n",
       "                        <td id=\"T_ea3f6_row4_col2\" class=\"data row4 col2\" >0.919816</td>\n",
       "                        <td id=\"T_ea3f6_row4_col3\" class=\"data row4 col3\" >0.919600</td>\n",
       "                        <td id=\"T_ea3f6_row4_col4\" class=\"data row4 col4\" >0.919708</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_ea3f6_row5_col0\" class=\"data row5 col0\" >SVM - LINEAR</td>\n",
       "                        <td id=\"T_ea3f6_row5_col1\" class=\"data row5 col1\" >0.948800</td>\n",
       "                        <td id=\"T_ea3f6_row5_col2\" class=\"data row5 col2\" >0.948800</td>\n",
       "                        <td id=\"T_ea3f6_row5_col3\" class=\"data row5 col3\" >0.948800</td>\n",
       "                        <td id=\"T_ea3f6_row5_col4\" class=\"data row5 col4\" >0.948800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_ea3f6_row6_col0\" class=\"data row6 col0\" >SVM - POLY</td>\n",
       "                        <td id=\"T_ea3f6_row6_col1\" class=\"data row6 col1\" >0.941600</td>\n",
       "                        <td id=\"T_ea3f6_row6_col2\" class=\"data row6 col2\" >0.941600</td>\n",
       "                        <td id=\"T_ea3f6_row6_col3\" class=\"data row6 col3\" >0.941600</td>\n",
       "                        <td id=\"T_ea3f6_row6_col4\" class=\"data row6 col4\" >0.941600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_ea3f6_row7_col0\" class=\"data row7 col0\" >SVM - RBF</td>\n",
       "                        <td id=\"T_ea3f6_row7_col1\" class=\"data row7 col1\" >0.942400</td>\n",
       "                        <td id=\"T_ea3f6_row7_col2\" class=\"data row7 col2\" >0.954386</td>\n",
       "                        <td id=\"T_ea3f6_row7_col3\" class=\"data row7 col3\" >0.942400</td>\n",
       "                        <td id=\"T_ea3f6_row7_col4\" class=\"data row7 col4\" >0.942400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_ea3f6_row8_col0\" class=\"data row8 col0\" >SVM - SIGMOID</td>\n",
       "                        <td id=\"T_ea3f6_row8_col1\" class=\"data row8 col1\" >0.946000</td>\n",
       "                        <td id=\"T_ea3f6_row8_col2\" class=\"data row8 col2\" >0.946000</td>\n",
       "                        <td id=\"T_ea3f6_row8_col3\" class=\"data row8 col3\" >0.946000</td>\n",
       "                        <td id=\"T_ea3f6_row8_col4\" class=\"data row8 col4\" >0.946000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_ea3f6_row9_col0\" class=\"data row9 col0\" >MVE</td>\n",
       "                        <td id=\"T_ea3f6_row9_col1\" class=\"data row9 col1\" >0.936400</td>\n",
       "                        <td id=\"T_ea3f6_row9_col2\" class=\"data row9 col2\" >0.968034</td>\n",
       "                        <td id=\"T_ea3f6_row9_col3\" class=\"data row9 col3\" >0.936400</td>\n",
       "                        <td id=\"T_ea3f6_row9_col4\" class=\"data row9 col4\" >0.936400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_ea3f6_row10_col0\" class=\"data row10 col0\" >ELM(10,TANH)</td>\n",
       "                        <td id=\"T_ea3f6_row10_col1\" class=\"data row10 col1\" >0.927600</td>\n",
       "                        <td id=\"T_ea3f6_row10_col2\" class=\"data row10 col2\" >0.927600</td>\n",
       "                        <td id=\"T_ea3f6_row10_col3\" class=\"data row10 col3\" >0.927600</td>\n",
       "                        <td id=\"T_ea3f6_row10_col4\" class=\"data row10 col4\" >0.927600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_ea3f6_row11_col0\" class=\"data row11 col0\" >ELM(10,TANH,LR)</td>\n",
       "                        <td id=\"T_ea3f6_row11_col1\" class=\"data row11 col1\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row11_col2\" class=\"data row11 col2\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row11_col3\" class=\"data row11 col3\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row11_col4\" class=\"data row11 col4\" >0.929200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_ea3f6_row12_col0\" class=\"data row12 col0\" >ELM(10,SINSQ)</td>\n",
       "                        <td id=\"T_ea3f6_row12_col1\" class=\"data row12 col1\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row12_col2\" class=\"data row12 col2\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row12_col3\" class=\"data row12 col3\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row12_col4\" class=\"data row12 col4\" >0.929200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_ea3f6_row13_col0\" class=\"data row13 col0\" >ELM(10,TRIBAS)</td>\n",
       "                        <td id=\"T_ea3f6_row13_col1\" class=\"data row13 col1\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row13_col2\" class=\"data row13 col2\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row13_col3\" class=\"data row13 col3\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row13_col4\" class=\"data row13 col4\" >0.929200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_ea3f6_row14_col0\" class=\"data row14 col0\" >ELM(HARDLIM)</td>\n",
       "                        <td id=\"T_ea3f6_row14_col1\" class=\"data row14 col1\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row14_col2\" class=\"data row14 col2\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row14_col3\" class=\"data row14 col3\" >0.929200</td>\n",
       "                        <td id=\"T_ea3f6_row14_col4\" class=\"data row14 col4\" >0.929200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ea3f6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_ea3f6_row15_col0\" class=\"data row15 col0\" >ANN-GD</td>\n",
       "                        <td id=\"T_ea3f6_row15_col1\" class=\"data row15 col1\" >0.935626</td>\n",
       "                        <td id=\"T_ea3f6_row15_col2\" class=\"data row15 col2\" >0.935626</td>\n",
       "                        <td id=\"T_ea3f6_row15_col3\" class=\"data row15 col3\" >0.935626</td>\n",
       "                        <td id=\"T_ea3f6_row15_col4\" class=\"data row15 col4\" >0.935626</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ef731c0ac0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.set_index('ML Method')\n",
    "df_metrics.style.apply(color, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a12d694c3ccac42055183a0ad11e659c6a2db5c6555ad2c8919d5814fd4e404f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
