{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color:dodgerblue; font-weight:700\"> Sentiment Analysis on Twitter Tweets</h1>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sentiment Analysis is conducted on various datasets after exploratory data analysis and data preprocessing, separately using variety of Machine Learning techniques</p>\n",
    "<h4 style=\"font-weight:600;\">15 implemented ML Algorithms : </h4>\n",
    "<ol>\n",
    "<li>Logistic Regression</li>\n",
    "<ul>\n",
    "<li>Newton CG</li>\n",
    "<li>SAG</li>\n",
    "<li>SAGA</li>\n",
    "<li>LBFGS</li>\n",
    "</ul>\n",
    "<li>Decision Tree Classifier</li>\n",
    "<li>Support Vector Machines</li>\n",
    "<ul>\n",
    "<li>Linear</li>\n",
    "<li>Poly</li>\n",
    "<li>RBF</li>\n",
    "<li>Sigmoid</li>\n",
    "</ul>\n",
    "<li>Majority Voting Ensemble</li>\n",
    "<li>Extreme Laerning Machines</li>\n",
    "<ul>\n",
    "<li>Tanh</li>\n",
    "<li>SinSQ</li>\n",
    "<li>Tribas</li>\n",
    "<li>Hardlim</li>\n",
    "</ul>\n",
    "<li>Artificial Neural Networks (Multi - Layer Perceptron) Gradient Descent</li>\n",
    "</ol>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<h2 align=\"center\" style=\"color:red\">Part 1 : Data Preprocessing</h2>\n",
    "<ol>\n",
    "<li>Exploratory Data Analysis</li>\n",
    "<li>Data Preprocessing</li>\n",
    "<li>Cleaning</li>\n",
    "<li>Lemmatization</li>\n",
    "</ol>\n",
    "<hr/>\n",
    "<style>\n",
    "li {\n",
    "    margin-left:100px;\n",
    "    /* color: yellow; */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Flow of Control</h4>\n",
    "<ol>\n",
    "<li>Sentence Segmentation</li=>\n",
    "<li>Word Tokenization</li=>\n",
    "<li>Same consecutive chars changed to max 2 times</li=>\n",
    "<li>Spelling Corrections</li>\n",
    "<li>Removal of #Hashtags, @Mentions, http//:URLs, etc (Noise 1)</li>\n",
    "<li>Removal of Special Unicode Characters (Noise 2)</li>\n",
    "<li>Chat Abbreviations conversions (Noise 3)</li>\n",
    "<li>Removal of Punctuations except `'` (Noise 4)</li>\n",
    "<li>Stop Words Removal (Noise 5)</li>\n",
    "<li>Parts of Speech Tagging</li>\n",
    "<li>Stemming & Lemmatization</li>\n",
    "<li>WhiteSpace Removals</li>\n",
    "<li>Chunking</li>\n",
    "</ol>\n",
    "<hr/>\n",
    "<style>\n",
    "h4 {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    color: green;\n",
    "    font-weight: 650;\n",
    "}\n",
    "li {\n",
    "    margin-left:100px;\n",
    "    /* color: yellow; */\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\" style=\"color:red\">Part 2 : Machine Learning Models Training</h2>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neccessary Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            filePath : str = \"\",\n",
    "            df : pd.DataFrame = None,\n",
    "            preprocessed : str = True,\n",
    "            name : str = \"\"\n",
    "        ) -> None:\n",
    "        \"\"\"Dataset\n",
    "            ======\n",
    "            Represents AI-ML datasets\n",
    "\n",
    "            Paramters\n",
    "            ---------\n",
    "            filePath : str - System Path to the file location (default '')\n",
    "            df : pd.DataFrame - Pandas DataFrame for the dataset (default None)\n",
    "            preprocessed : str - Indicates whether data is raw or processed, Possible values = ('raw', 'pro')\n",
    "            name : str - Given name for the dataset\n",
    "        \"\"\"\n",
    "        self.filePath = filePath\n",
    "        self.name = name if name else filePath\n",
    "        self.df = df\n",
    "        self.preprocessed = preprocessed\n",
    "    \n",
    "\n",
    "\n",
    "    def loadDataset(self, filePath : str = 'default'):\n",
    "        if filePath:\n",
    "            self.filePath = filePath\n",
    "            if not self.name: self.name = filePath\n",
    "        if self.filePath is None:\n",
    "            raise(\"Path to dataset file not provided\")\n",
    "        try:\n",
    "            self.df = pd.read_csv(filePath)\n",
    "        except Exception as e:\n",
    "            print(f\"Cannot import dataset named {self.name} from path {self.filePath}\")\n",
    "            print(f\"Original Error : {e}\")\n",
    "            traceback.print_exception()\n",
    "    \n",
    "\n",
    "    def get_DF(self):\n",
    "        if self.df is None:\n",
    "            self.loadDataset()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"dataset_1\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_1_processed.csv\", name = \"dataset_1\"),\n",
    "        \"trainingDone\" : True\n",
    "    },\n",
    "\n",
    "    \"dataset_2\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_2_processed.csv\", name = \"dataset_2\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "\n",
    "    \"dataset_3\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_3_processed.csv\", name = \"dataset_3\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "\n",
    "    \"dataset_4\" : {\n",
    "        \"dataset\" : Dataset(\"./data/dataset_4_processed.csv\", name = \"dataset_4\"),\n",
    "        \"trainingDone\" : False\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTwe = pd.read_csv(\"./data/dataset_2_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dfTwe.index:\n",
    "    if type(dfTwe.loc[idx, \"Proc_Tweet\"]) != str:\n",
    "        dfTwe.loc[idx, \"Proc_Tweet\"] = \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3873\n",
       "Name: Proc_Tweet, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTwe[\"Proc_Tweet\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digitalize Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\n",
    "    'fun' : 1, 'happiness' : 1, 'love' : 1, 'relief' : 1, 'enthusiasm' : 1, 'surprise' : 1,\n",
    "    'empty' : 0, 'neutral' : 0,\n",
    "    'boredom' : -1, 'anger' : -1, 'hate' : -1, 'sadness' : -1, 'worry' : -1\n",
    "}\n",
    "\n",
    "def digitalize(sent : str):\n",
    "    return sents.get(sent, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(dfTwe.loc[0, \"sentiment\"]) == str:\n",
    "    dfTwe[\"sentiment\"] = dfTwe[\"sentiment\"].apply(digitalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfTwe[\"Proc_Tweet\"][:10000]\n",
    "y = dfTwe[\"sentiment\"] [:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2904,), (969,), (2904,), (969,))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(ML_Model, y_test, y_pred):\n",
    "    results = {\n",
    "        \"ML Model\" : ML_Model,\n",
    "        \"classification_report\"  : classification_report(y_test, y_pred),\n",
    "        \"accuracy_score\"  : accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    funcs = (precision_score, recall_score, f1_score,)\n",
    "    params = (\"micro\", \"macro\", \"weighted\",)\n",
    "\n",
    "    for func in funcs:\n",
    "        results[func.__name__] = {}\n",
    "        for param in params:\n",
    "            results[func.__name__][param] = func(y_test, y_pred, average = param)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Classifier(ML_Method, x_train = x_train, x_test = x_test, y_train = y_train, y_test = y_test):\n",
    "    model = make_pipeline(TfidfVectorizer(ngram_range=(1, 3)), ML_Method)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return generate_results(model, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGR_solvers = ('newton-cg', 'sag', 'saga', 'lbfgs',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slvr in LOGR_solvers:\n",
    "    result_LOGR = Text_Classifier(LogisticRegression(random_state = 0, solver = slvr, multi_class = 'auto'))\n",
    "    ML_results[f\"LOGR_{slvr}\"] = result_LOGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_DT = Text_Classifier(DecisionTreeClassifier())\n",
    "ML_results['Decision_Tree'] = result_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_Kernels = ['linear', 'poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for krnl in SVM_Kernels:\n",
    "    try:\n",
    "        result_SVM = Text_Classifier(SVC(kernel=krnl))\n",
    "        ML_results[f\"SVM_{krnl}\"] = result_SVM\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_MVE = Text_Classifier(VotingClassifier(estimators = [\n",
    "    ('lr', LogisticRegression(random_state = 0, solver = 'lbfgs', multi_class = 'auto')),\n",
    "    ('svm', SVC(kernel=\"rbf\"))\n",
    "]))\n",
    "ML_results[\"MVE\"] = result_MVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Learning Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ELM(10,tanh) Successful, metrics saved\n",
      "Model ELM(10,tanh,LR) failed with error : y should be a 1d array, got an array of shape (2904, 3) instead.\n",
      "Model ELM(10,sinsq) Successful, metrics saved\n",
      "Model ELM(10,tribas) Successful, metrics saved\n",
      "Model ELM(hardlim) Successful, metrics saved\n",
      "Model ELM(20,rbf(0.1)) failed with error : unsupported operand type(s) for -: 'map' and 'map'\n"
     ]
    }
   ],
   "source": [
    "def make_classifiers():\n",
    "    nh : int = 10\n",
    "\n",
    "    # Custom (user defined) transfer function\n",
    "    sinsq = (lambda x: np.power(np.sin(x), 2.0))\n",
    "    srhl_sinsq = MLPRandomLayer(n_hidden=nh, activation_func=sinsq)\n",
    "\n",
    "    # Internal Transfer functions\n",
    "    srhl_tanh = MLPRandomLayer(n_hidden=nh, activation_func='tanh')\n",
    "    srhl_tribas = MLPRandomLayer(n_hidden=nh, activation_func='tribas')\n",
    "    srhl_hardlim = MLPRandomLayer(n_hidden=nh, activation_func='hardlim')\n",
    "\n",
    "    # Gaussian RBF\n",
    "    srhl_rbf = RBFRandomLayer(n_hidden=nh*2, rbf_width=0.1, random_state=0)\n",
    "    \n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    classifiers = [\n",
    "        ('ELM(10,tanh)', GenELMClassifier(hidden_layer=srhl_tanh)),\n",
    "        ('ELM(10,tanh,LR)', GenELMClassifier(hidden_layer=srhl_tanh, regressor=log_reg)),\n",
    "        ('ELM(10,sinsq)', GenELMClassifier(hidden_layer=srhl_sinsq)),\n",
    "        ('ELM(10,tribas)', GenELMClassifier(hidden_layer=srhl_tribas)),\n",
    "        ('ELM(hardlim)', GenELMClassifier(hidden_layer=srhl_hardlim)),\n",
    "        ('ELM(20,rbf(0.1))', GenELMClassifier(hidden_layer=srhl_rbf)),\n",
    "    ]\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = [dfTwe[\"Proc_Tweet\"].to_list(), dfTwe[\"sentiment\"].to_list()]\n",
    "    names, classifiers = zip(*make_classifiers())\n",
    "\n",
    "\n",
    "    X, y = dataset\n",
    "    vectorizer = TfidfVectorizer(min_df=3, sublinear_tf=True, norm='l2', ngram_range=(1, 3))\n",
    "    X = vectorizer.fit_transform(X)[:10000]\n",
    "    y = y[:10000]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=3)\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        try:\n",
    "            clf.fit(x_train, y_train)\n",
    "            # score = clf.score(x_test, y_test)\n",
    "            y_pred = clf.predict(x_test)\n",
    "            print(f'Model {name} Successful, metrics saved')\n",
    "            ML_results[name] = generate_results(clf, y_test, y_pred)\n",
    "\n",
    "        except Exception as e: print(f'Model {name} failed with error : {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfTwe[\"Proc_Tweet\"]#[:10000]\n",
    "y = dfTwe[\"sentiment\"] #[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2904, 1991), (969, 1991), (2904,), (969,))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='sgd', random_state=20, hidden_layer_sizes=(15,12), alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 12), random_state=20,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 10000\n",
    "clf.fit(x_train[:sz], y_train[:sz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_results['ANN-GD'] = generate_results(clf, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Metrics Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- LOGR_newton-cg --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='newton-cg'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       287\n",
      "           0       0.82      0.97      0.89       385\n",
      "           1       0.93      0.80      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.90      0.87      0.88       969\n",
      "weighted avg       0.89      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8823529411764706\n",
      "precision_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8998225424793714, 'weighted': 0.8917134995375263}\n",
      "recall_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8728985558253851, 'weighted': 0.8823529411764706}\n",
      "f1_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.881368287869326, 'weighted': 0.881852252305253}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_sag --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='sag'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       287\n",
      "           0       0.82      0.97      0.89       385\n",
      "           1       0.93      0.80      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.90      0.87      0.88       969\n",
      "weighted avg       0.89      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8823529411764706\n",
      "precision_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8998225424793714, 'weighted': 0.8917134995375263}\n",
      "recall_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8728985558253851, 'weighted': 0.8823529411764706}\n",
      "f1_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.881368287869326, 'weighted': 0.881852252305253}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_saga --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(random_state=0, solver='saga'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       287\n",
      "           0       0.82      0.97      0.89       385\n",
      "           1       0.93      0.80      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.90      0.87      0.88       969\n",
      "weighted avg       0.89      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8823529411764706\n",
      "precision_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8998225424793714, 'weighted': 0.8917134995375263}\n",
      "recall_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8728985558253851, 'weighted': 0.8823529411764706}\n",
      "f1_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.881368287869326, 'weighted': 0.881852252305253}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- LOGR_lbfgs --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('logisticregression', LogisticRegression(random_state=0))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       287\n",
      "           0       0.82      0.97      0.89       385\n",
      "           1       0.93      0.80      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.90      0.87      0.88       969\n",
      "weighted avg       0.89      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8823529411764706\n",
      "precision_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8998225424793714, 'weighted': 0.8917134995375263}\n",
      "recall_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8728985558253851, 'weighted': 0.8823529411764706}\n",
      "f1_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.881368287869326, 'weighted': 0.881852252305253}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- Decision_Tree --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('decisiontreeclassifier', DecisionTreeClassifier())])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.84      0.86       287\n",
      "           0       0.89      0.60      0.72       385\n",
      "           1       0.61      0.89      0.72       297\n",
      "\n",
      "    accuracy                           0.76       969\n",
      "   macro avg       0.79      0.78      0.76       969\n",
      "weighted avg       0.80      0.76      0.76       969\n",
      "\n",
      "accuracy_score\n",
      "0.7585139318885449\n",
      "precision_score\n",
      "{'micro': 0.7585139318885449, 'macro': 0.7902719860784377, 'weighted': 0.7983006384074994}\n",
      "recall_score\n",
      "{'micro': 0.7585139318885449, 'macro': 0.775081046625762, 'weighted': 0.7585139318885449}\n",
      "f1_score\n",
      "{'micro': 0.758513931888545, 'macro': 0.7644975196070317, 'weighted': 0.7591572091371354}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_linear --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='linear'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.84      0.89       287\n",
      "           0       0.84      0.95      0.89       385\n",
      "           1       0.89      0.82      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.89      0.87      0.88       969\n",
      "weighted avg       0.88      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8802889576883385\n",
      "precision_score\n",
      "{'micro': 0.8802889576883385, 'macro': 0.8902262473383239, 'weighted': 0.8849079110460694}\n",
      "recall_score\n",
      "{'micro': 0.8802889576883385, 'macro': 0.8726279441726597, 'weighted': 0.8802889576883385}\n",
      "f1_score\n",
      "{'micro': 0.8802889576883385, 'macro': 0.8787687624320467, 'weighted': 0.8798488906035885}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_poly --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='poly'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.29      0.44       287\n",
      "           0       0.50      0.99      0.67       385\n",
      "           1       0.93      0.38      0.54       297\n",
      "\n",
      "    accuracy                           0.60       969\n",
      "   macro avg       0.79      0.56      0.55       969\n",
      "weighted avg       0.76      0.60      0.56       969\n",
      "\n",
      "accuracy_score\n",
      "0.5975232198142415\n",
      "precision_score\n",
      "{'micro': 0.5975232198142415, 'macro': 0.7871949114893754, 'weighted': 0.760130821596359}\n",
      "recall_score\n",
      "{'micro': 0.5975232198142415, 'macro': 0.555120699836147, 'weighted': 0.5975232198142415}\n",
      "f1_score\n",
      "{'micro': 0.5975232198142415, 'macro': 0.5513720174057533, 'weighted': 0.5631580775847971}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_rbf --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC())])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.84      0.90       287\n",
      "           0       0.82      0.96      0.88       385\n",
      "           1       0.88      0.80      0.84       297\n",
      "\n",
      "    accuracy                           0.87       969\n",
      "   macro avg       0.89      0.87      0.87       969\n",
      "weighted avg       0.88      0.87      0.87       969\n",
      "\n",
      "accuracy_score\n",
      "0.8740970072239422\n",
      "precision_score\n",
      "{'micro': 0.8740970072239422, 'macro': 0.8881722786644906, 'weighted': 0.8812018867576126}\n",
      "recall_score\n",
      "{'micro': 0.8740970072239422, 'macro': 0.865637403848786, 'weighted': 0.8740970072239422}\n",
      "f1_score\n",
      "{'micro': 0.8740970072239422, 'macro': 0.8731313949195313, 'weighted': 0.8737465815156588}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- SVM_sigmoid --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('svc', SVC(kernel='sigmoid'))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.84      0.89       287\n",
      "           0       0.83      0.96      0.89       385\n",
      "           1       0.90      0.81      0.85       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.89      0.87      0.88       969\n",
      "weighted avg       0.88      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8792569659442725\n",
      "precision_score\n",
      "{'micro': 0.8792569659442725, 'macro': 0.8907068851668623, 'weighted': 0.884803211052133}\n",
      "recall_score\n",
      "{'micro': 0.8792569659442725, 'macro': 0.8707360089473911, 'weighted': 0.8792569659442725}\n",
      "f1_score\n",
      "{'micro': 0.8792569659442725, 'macro': 0.8774415839992575, 'weighted': 0.8786188557797645}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- MVE --------------------------------------------------\n",
      "ML Model\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
      "                ('votingclassifier',\n",
      "                 VotingClassifier(estimators=[('lr',\n",
      "                                               LogisticRegression(random_state=0)),\n",
      "                                              ('svm', SVC())]))])\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       287\n",
      "           0       0.81      0.98      0.89       385\n",
      "           1       0.94      0.78      0.86       297\n",
      "\n",
      "    accuracy                           0.88       969\n",
      "   macro avg       0.90      0.87      0.88       969\n",
      "weighted avg       0.89      0.88      0.88       969\n",
      "\n",
      "accuracy_score\n",
      "0.8823529411764706\n",
      "precision_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.9032806037571889, 'weighted': 0.8942425656127496}\n",
      "recall_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8718724214659175, 'weighted': 0.8823529411764706}\n",
      "f1_score\n",
      "{'micro': 0.8823529411764706, 'macro': 0.8811941438546974, 'weighted': 0.8816923783635597}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,tanh) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.34      0.07      0.12       270\n",
      "           0       0.44      0.76      0.56       386\n",
      "           1       0.51      0.40      0.45       313\n",
      "\n",
      "    accuracy                           0.45       969\n",
      "   macro avg       0.43      0.41      0.38       969\n",
      "weighted avg       0.44      0.45      0.40       969\n",
      "\n",
      "accuracy_score\n",
      "0.4540763673890609\n",
      "precision_score\n",
      "{'micro': 0.4540763673890609, 'macro': 0.4299292608779692, 'weighted': 0.43508389180829576}\n",
      "recall_score\n",
      "{'micro': 0.4540763673890609, 'macro': 0.4127626719017627, 'weighted': 0.4540763673890609}\n",
      "f1_score\n",
      "{'micro': 0.4540763673890609, 'macro': 0.3771945693840461, 'weighted': 0.4024302082520852}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,sinsq) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.13      0.20       270\n",
      "           0       0.42      0.86      0.57       386\n",
      "           1       0.42      0.14      0.21       313\n",
      "\n",
      "    accuracy                           0.42       969\n",
      "   macro avg       0.43      0.38      0.33       969\n",
      "weighted avg       0.43      0.42      0.35       969\n",
      "\n",
      "accuracy_score\n",
      "0.4231166150670795\n",
      "precision_score\n",
      "{'micro': 0.4231166150670795, 'macro': 0.4284894464320015, 'weighted': 0.42707699703253116}\n",
      "recall_score\n",
      "{'micro': 0.4231166150670795, 'macro': 0.3759058876232366, 'weighted': 0.4231166150670795}\n",
      "f1_score\n",
      "{'micro': 0.4231166150670795, 'macro': 0.3255006901524417, 'weighted': 0.3490864020843729}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(10,tribas) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.13      0.20       270\n",
      "           0       0.44      0.78      0.56       386\n",
      "           1       0.44      0.30      0.36       313\n",
      "\n",
      "    accuracy                           0.44       969\n",
      "   macro avg       0.45      0.40      0.37       969\n",
      "weighted avg       0.45      0.44      0.39       969\n",
      "\n",
      "accuracy_score\n",
      "0.44169246646026833\n",
      "precision_score\n",
      "{'micro': 0.44169246646026833, 'macro': 0.44962210933189106, 'weighted': 0.4480410234855925}\n",
      "recall_score\n",
      "{'micro': 0.44169246646026833, 'macro': 0.400947757559631, 'weighted': 0.44169246646026833}\n",
      "f1_score\n",
      "{'micro': 0.44169246646026833, 'macro': 0.3718721234555154, 'weighted': 0.3938280084215772}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ELM(hardlim) --------------------------------------------------\n",
      "ML Model\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.46      0.26      0.33       270\n",
      "           0       0.46      0.66      0.54       386\n",
      "           1       0.47      0.40      0.43       313\n",
      "\n",
      "    accuracy                           0.46       969\n",
      "   macro avg       0.46      0.44      0.43       969\n",
      "weighted avg       0.46      0.46      0.45       969\n",
      "\n",
      "accuracy_score\n",
      "0.4613003095975232\n",
      "precision_score\n",
      "{'micro': 0.4613003095975232, 'macro': 0.46363830151003116, 'weighted': 0.46305476549118646}\n",
      "recall_score\n",
      "{'micro': 0.4613003095975232, 'macro': 0.43695526931744494, 'weighted': 0.4613003095975232}\n",
      "f1_score\n",
      "{'micro': 0.4613003095975232, 'macro': 0.43360764894781373, 'weighted': 0.44593630554518177}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------------- ANN-GD --------------------------------------------------\n",
      "ML Model\n",
      "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15, 12), random_state=20,\n",
      "              solver='sgd')\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.08      0.14       297\n",
      "           0       0.46      1.00      0.63       385\n",
      "           1       1.00      0.35      0.52       287\n",
      "\n",
      "    accuracy                           0.52       969\n",
      "   macro avg       0.82      0.48      0.43       969\n",
      "weighted avg       0.78      0.52      0.45       969\n",
      "\n",
      "accuracy_score\n",
      "0.5242518059855521\n",
      "precision_score\n",
      "{'micro': 0.5242518059855521, 'macro': 0.818360914105595, 'weighted': 0.7834952072156472}\n",
      "recall_score\n",
      "{'micro': 0.5242518059855521, 'macro': 0.4752910443967355, 'weighted': 0.5242518059855521}\n",
      "f1_score\n",
      "{'micro': 0.5242518059855521, 'macro': 0.4286845276453602, 'weighted': 0.4456497777072752}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for meth, result in ML_results.items():\n",
    "    try:\n",
    "        print('-'*50 + \" \" + meth + \" \" + '-'*50)\n",
    "        for k, v in result.items():\n",
    "            try:\n",
    "                print(k)\n",
    "                print(v)\n",
    "            except: pass\n",
    "        print('-'*100)\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Centred Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = {\n",
    "    'ML Method' : [],\n",
    "    'Accuracy' : [],\n",
    "    'Precision' : [],\n",
    "    'Recall' : [],\n",
    "    'F1-Score' : [],\n",
    "}\n",
    "\n",
    "for meth, result in ML_results.items():\n",
    "    metrics_table['ML Method'].append(meth)\n",
    "    metrics_table['Accuracy'].append(result['accuracy_score'])\n",
    "    metrics_table['Precision'].append(max(result['precision_score'].values()))\n",
    "    metrics_table['Recall'].append(max(result['recall_score'].values()))\n",
    "    metrics_table['F1-Score'].append(max(result['f1_score'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df_metrics.index:\n",
    "    df_metrics.loc[idx, :] = df_metrics.loc[idx, :].apply(lambda val : val.replace('_', ' - ').upper() if type(val) == str else val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(x):\n",
    "    df_metrics.style.set_properties(**{'color': 'cyan'}, subset=['ML Method'])\n",
    "    # mask  =  df_metrics['Win %'] > 0\n",
    "    # mask1 =  df_metrics['Win %'] == 0\n",
    "    # mask2 =  df_metrics['Win %'] < 0\n",
    "    x = pd.DataFrame('', index=df_metrics.index, columns=df_metrics.columns)\n",
    "    x.loc[:, 'ML Method'] = 'color: cyan'\n",
    "    # x.loc[mask1,['Win %']] = 'color: cyan'\n",
    "    # x.loc[mask2,['Win %']] = 'color: red'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_913ff_row0_col0,#T_913ff_row1_col0,#T_913ff_row2_col0,#T_913ff_row3_col0,#T_913ff_row4_col0,#T_913ff_row5_col0,#T_913ff_row6_col0,#T_913ff_row7_col0,#T_913ff_row8_col0,#T_913ff_row9_col0,#T_913ff_row10_col0,#T_913ff_row11_col0,#T_913ff_row12_col0,#T_913ff_row13_col0,#T_913ff_row14_col0{\n",
       "            color:  cyan;\n",
       "        }</style><table id=\"T_913ff_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >ML Method</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >F1-Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_913ff_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_913ff_row0_col0\" class=\"data row0 col0\" >LOGR - NEWTON-CG</td>\n",
       "                        <td id=\"T_913ff_row0_col1\" class=\"data row0 col1\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row0_col2\" class=\"data row0 col2\" >0.899823</td>\n",
       "                        <td id=\"T_913ff_row0_col3\" class=\"data row0 col3\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row0_col4\" class=\"data row0 col4\" >0.882353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_913ff_row1_col0\" class=\"data row1 col0\" >LOGR - SAG</td>\n",
       "                        <td id=\"T_913ff_row1_col1\" class=\"data row1 col1\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row1_col2\" class=\"data row1 col2\" >0.899823</td>\n",
       "                        <td id=\"T_913ff_row1_col3\" class=\"data row1 col3\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row1_col4\" class=\"data row1 col4\" >0.882353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_913ff_row2_col0\" class=\"data row2 col0\" >LOGR - SAGA</td>\n",
       "                        <td id=\"T_913ff_row2_col1\" class=\"data row2 col1\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row2_col2\" class=\"data row2 col2\" >0.899823</td>\n",
       "                        <td id=\"T_913ff_row2_col3\" class=\"data row2 col3\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row2_col4\" class=\"data row2 col4\" >0.882353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_913ff_row3_col0\" class=\"data row3 col0\" >LOGR - LBFGS</td>\n",
       "                        <td id=\"T_913ff_row3_col1\" class=\"data row3 col1\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row3_col2\" class=\"data row3 col2\" >0.899823</td>\n",
       "                        <td id=\"T_913ff_row3_col3\" class=\"data row3 col3\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row3_col4\" class=\"data row3 col4\" >0.882353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_913ff_row4_col0\" class=\"data row4 col0\" >DECISION - TREE</td>\n",
       "                        <td id=\"T_913ff_row4_col1\" class=\"data row4 col1\" >0.758514</td>\n",
       "                        <td id=\"T_913ff_row4_col2\" class=\"data row4 col2\" >0.798301</td>\n",
       "                        <td id=\"T_913ff_row4_col3\" class=\"data row4 col3\" >0.775081</td>\n",
       "                        <td id=\"T_913ff_row4_col4\" class=\"data row4 col4\" >0.764498</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_913ff_row5_col0\" class=\"data row5 col0\" >SVM - LINEAR</td>\n",
       "                        <td id=\"T_913ff_row5_col1\" class=\"data row5 col1\" >0.880289</td>\n",
       "                        <td id=\"T_913ff_row5_col2\" class=\"data row5 col2\" >0.890226</td>\n",
       "                        <td id=\"T_913ff_row5_col3\" class=\"data row5 col3\" >0.880289</td>\n",
       "                        <td id=\"T_913ff_row5_col4\" class=\"data row5 col4\" >0.880289</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_913ff_row6_col0\" class=\"data row6 col0\" >SVM - POLY</td>\n",
       "                        <td id=\"T_913ff_row6_col1\" class=\"data row6 col1\" >0.597523</td>\n",
       "                        <td id=\"T_913ff_row6_col2\" class=\"data row6 col2\" >0.787195</td>\n",
       "                        <td id=\"T_913ff_row6_col3\" class=\"data row6 col3\" >0.597523</td>\n",
       "                        <td id=\"T_913ff_row6_col4\" class=\"data row6 col4\" >0.597523</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_913ff_row7_col0\" class=\"data row7 col0\" >SVM - RBF</td>\n",
       "                        <td id=\"T_913ff_row7_col1\" class=\"data row7 col1\" >0.874097</td>\n",
       "                        <td id=\"T_913ff_row7_col2\" class=\"data row7 col2\" >0.888172</td>\n",
       "                        <td id=\"T_913ff_row7_col3\" class=\"data row7 col3\" >0.874097</td>\n",
       "                        <td id=\"T_913ff_row7_col4\" class=\"data row7 col4\" >0.874097</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_913ff_row8_col0\" class=\"data row8 col0\" >SVM - SIGMOID</td>\n",
       "                        <td id=\"T_913ff_row8_col1\" class=\"data row8 col1\" >0.879257</td>\n",
       "                        <td id=\"T_913ff_row8_col2\" class=\"data row8 col2\" >0.890707</td>\n",
       "                        <td id=\"T_913ff_row8_col3\" class=\"data row8 col3\" >0.879257</td>\n",
       "                        <td id=\"T_913ff_row8_col4\" class=\"data row8 col4\" >0.879257</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_913ff_row9_col0\" class=\"data row9 col0\" >MVE</td>\n",
       "                        <td id=\"T_913ff_row9_col1\" class=\"data row9 col1\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row9_col2\" class=\"data row9 col2\" >0.903281</td>\n",
       "                        <td id=\"T_913ff_row9_col3\" class=\"data row9 col3\" >0.882353</td>\n",
       "                        <td id=\"T_913ff_row9_col4\" class=\"data row9 col4\" >0.882353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_913ff_row10_col0\" class=\"data row10 col0\" >ELM(10,TANH)</td>\n",
       "                        <td id=\"T_913ff_row10_col1\" class=\"data row10 col1\" >0.454076</td>\n",
       "                        <td id=\"T_913ff_row10_col2\" class=\"data row10 col2\" >0.454076</td>\n",
       "                        <td id=\"T_913ff_row10_col3\" class=\"data row10 col3\" >0.454076</td>\n",
       "                        <td id=\"T_913ff_row10_col4\" class=\"data row10 col4\" >0.454076</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_913ff_row11_col0\" class=\"data row11 col0\" >ELM(10,SINSQ)</td>\n",
       "                        <td id=\"T_913ff_row11_col1\" class=\"data row11 col1\" >0.423117</td>\n",
       "                        <td id=\"T_913ff_row11_col2\" class=\"data row11 col2\" >0.428489</td>\n",
       "                        <td id=\"T_913ff_row11_col3\" class=\"data row11 col3\" >0.423117</td>\n",
       "                        <td id=\"T_913ff_row11_col4\" class=\"data row11 col4\" >0.423117</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_913ff_row12_col0\" class=\"data row12 col0\" >ELM(10,TRIBAS)</td>\n",
       "                        <td id=\"T_913ff_row12_col1\" class=\"data row12 col1\" >0.441692</td>\n",
       "                        <td id=\"T_913ff_row12_col2\" class=\"data row12 col2\" >0.449622</td>\n",
       "                        <td id=\"T_913ff_row12_col3\" class=\"data row12 col3\" >0.441692</td>\n",
       "                        <td id=\"T_913ff_row12_col4\" class=\"data row12 col4\" >0.441692</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_913ff_row13_col0\" class=\"data row13 col0\" >ELM(HARDLIM)</td>\n",
       "                        <td id=\"T_913ff_row13_col1\" class=\"data row13 col1\" >0.461300</td>\n",
       "                        <td id=\"T_913ff_row13_col2\" class=\"data row13 col2\" >0.463638</td>\n",
       "                        <td id=\"T_913ff_row13_col3\" class=\"data row13 col3\" >0.461300</td>\n",
       "                        <td id=\"T_913ff_row13_col4\" class=\"data row13 col4\" >0.461300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_913ff_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_913ff_row14_col0\" class=\"data row14 col0\" >ANN-GD</td>\n",
       "                        <td id=\"T_913ff_row14_col1\" class=\"data row14 col1\" >0.524252</td>\n",
       "                        <td id=\"T_913ff_row14_col2\" class=\"data row14 col2\" >0.818361</td>\n",
       "                        <td id=\"T_913ff_row14_col3\" class=\"data row14 col3\" >0.524252</td>\n",
       "                        <td id=\"T_913ff_row14_col4\" class=\"data row14 col4\" >0.524252</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2555b1e52e0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.set_index('ML Method')\n",
    "df_metrics.style.apply(color, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a12d694c3ccac42055183a0ad11e659c6a2db5c6555ad2c8919d5814fd4e404f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
